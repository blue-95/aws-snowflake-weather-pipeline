# aws-snowflake-weather-pipeline

ğŸŒ©ï¸ Cloud-Native Weather Data Pipeline (AWS + Snowflake)

ğŸ“Œ Overview

This project implements an end-to-end cloud data engineering pipeline that ingests real-time weather data from an external API, stages it in AWS S3, and automatically loads it into Snowflake using Snowpipe.

The pipeline demonstrates production-grade ELT design, secure cloud integrations, and automated ingestion patterns commonly used in large-scale data platforms.

ğŸ—ï¸ Architecture

Flow:

<img width="906" height="338" alt="image" src="https://github.com/user-attachments/assets/80ab248f-6e93-4167-9009-ee071350c7fc" />


Key Design Principles:
	â€¢	Serverless ingestion
	â€¢	Immutable raw data storage
	â€¢	Automated, event-driven loading
	â€¢	Secure IAM-based access

â¸»

âš™ï¸ Tech Stack
	â€¢	AWS Lambda (Python)
	â€¢	Amazon S3
	â€¢	Snowflake (Snowpipe, External Stage, Storage Integration)
	â€¢	SQL
	â€¢	IAM (AWS Security)
	â€¢	JSON Data Format

â¸»

ğŸ“‚ Data Flow Breakdown
	1.	AWS Lambda fetches weather data from an external API
	2.	Raw JSON files are written to an S3 raw/ folder
	3.	Snowflake Storage Integration securely connects to S3
	4.	External Stage references the S3 raw location
	5.	Snowpipe automatically ingests new files into Snowflake
	6.	Data is stored in a structured Snowflake table for analytics


  ğŸ” Security & Governance
	â€¢	IAM Role-based access between AWS and Snowflake
	â€¢	Explicit S3 location whitelisting
	â€¢	Separation of compute, storage, and ingestion layers
	â€¢	Raw data preserved for reproducibility

â¸»

ğŸ¯ Why This Project Matters
	â€¢	Demonstrates real-world data engineering workflows
	â€¢	Shows ability to work across cloud platforms
	â€¢	Emphasizes reproducibility and data provenance
	â€¢	Designed to scale for ML and analytics workloads

â¸»

ğŸš€ Future Enhancements
	â€¢	Add data quality checks
	â€¢	Partitioned Snowflake tables
	â€¢	dbt transformations
	â€¢	ML feature extraction layer
	â€¢	Monitoring & alerting


